# Copyright (c) 2022, salesforce.com, inc.
# All rights reserved.
# SPDX-License-Identifier: BSD-3-Clause
# For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause

model:
  arch: blip2 #adapted for single GPU
  model_type: pretrain
  load_pretrained: False #pretrain from scratch
  freeze_vit: True
  vit_model: biovil
  vit_model_cls: [pubmedclip]
  num_query_token: 32
  max_txt_len: 256
  load_finetuned: True
  # finetuned: "pretraining/outputs/stage1_pt_instruct_blip_origlr_img448/checkpoint_4.pth"
  # finetuned: "pretraining/outputs/stage1_pt_instruct_blip_origlr_img448_1110_141106/checkpoint_9.pth"
  finetuned: "pretraining/outputs/stage1_pt_instruct_blip_origlr_img448_1205_005710/checkpoint_7.pth"

  llm:
    lora_path: "/home/cse/Documents/meta-cxr/Git_Repo/meta-cxr/checkpoints/lora-vicuna-7b-report-20250621"

  mhcac:
    threshold_path: "/home/cse/Documents/meta-cxr/Git_Repo/meta-cxr/threshold.json"

datasets:
  mimic_cxr: # name of the dataset builder
    vis_processor:
      train:
        name: "blip2_image_train"
        image_size: 448 #364
      eval:
        name: "blip_image_eval"
        image_size: 448 #364
    text_processor:
      train:
        name: "my_blip_caption"
        prompt: ''
      eval:
        name: "my_blip_caption"
        prompt: ''

run:
  task: image_text_pretrain_eval
  project_name: sample
  wandb_entity:
  run_name: stage1_pt_instruct_blip_origlr_img448
  # optimizer
  lr_sched: "linear_warmup_cosine_lr"
  init_lr_cls: 2e-4
  init_lr_q: 2e-4
  init_lr: 1e-4
  min_lr: 1e-5 #1e-5
  warmup_lr: 5e-5

# for 128 batch size
  # lr_sched: "linear_warmup_cosine_lr"
  # init_lr_cls: 1e-3
  # init_lr_q: 1e-3
  # init_lr: 1e-3
  # min_lr: 1e-4 #1e-5
  # warmup_lr: 5e-4
  

  weight_decay: 0.02
  max_epoch: 10
  batch_size_train: 32 #100
  batch_size_eval: 32 #64
  num_workers: 0 #4
  warmup_steps: 4000 #4500 for 32 bz

  max_len: 256 # how much tokens do general reports have: mean len (characters): 485 -> max: 2500 -> in tokens: 1000 tokens are around 250 tokens (only 1.2% of reports are longer than this)
  min_len: 8
  num_beams: 1

  seed: 42
  output_dir: "output/BLIP2/Pretrain_stage1"

  amp: True
  accum_grad_iters: 4
  resume_ckpt_path: "pretraining/outputs/stage1_pt_instruct_blip_origlr_img448/checkpoint_4.pth"
  # resume_ckpt_path:  "pretraining/outputs/stage1_pt_instruct_blip_origlr_img448_1130_094125/checkpoint_5.pth"
  finetune_classifier: True

  evaluate: True # make it True to evalute. check pretrain.train.py
  train_splits: [ "train" ]
  valid_splits: [ "val" ]

  device: "cuda"
  world_size: 1
  dist_url: "env://"
  distributed: False

